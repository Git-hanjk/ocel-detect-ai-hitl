# LLM configuration (starter)
model: "gpt-4.1-mini"
temperature: 0.2
max_tokens: 3000
